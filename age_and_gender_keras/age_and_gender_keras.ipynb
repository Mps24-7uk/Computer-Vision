{"cells":[{"metadata":{},"cell_type":"markdown","source":"find the dataset [here](https://www.kaggle.com/gpucloud/imdb-wiki)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input/imdb-db\"))","execution_count":1,"outputs":[{"output_type":"stream","text":"['imdb_db.mat']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import merge, Input\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy.io import loadmat\nfrom datetime import datetime\n\nfrom keras.models import load_model, Model\nfrom keras.utils import np_utils","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transfer learning\nmodel = load_model(\"../input/weights/weights.29-3.76_utk.hdf5\")","execution_count":3,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#last_layer\nlast_layer = model.get_layer('average_pooling2d_1').output","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(path):\n    d = loadmat(path)\n    return d[\"image\"], d[\"gender\"][0], d[\"age\"][0], d[\"db\"][0], d[\"img_size\"][0, 0], d[\"min_score\"][0, 0]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image, gender, age, _, image_size, _ = load_data(\"../input/imdb-db/imdb_db\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data = image\ny_data_g = np_utils.to_categorical(gender, 2)\ny_data_a = np_utils.to_categorical(age, 101)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_input = Input(shape=(64, 64, 3))\nx= Flatten(name='flatten')(last_layer)\nx = Dense(128, activation='relu', name='fc1')(x)\n#dense layer for gender prediction\npredictions_g = Dense(2, activation='softmax', name='gender')(x)\n\n#dense layer for age prediction\npredictions_a = Dense(101, activation='softmax', name='age')(x)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use the output layer for both gender prediction age prediction\nmodel_custom = Model(model.get_layer('input_1').output, [predictions_a, predictions_g])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_custom.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 64, 64, 16)   432         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 64, 64, 128)  18432       activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 64, 64, 128)  147456      activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 64, 64, 128)  2048        activation_1[0][0]               \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n                                                                 conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 64, 64, 128)  512         add_1[0][0]                      \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 64, 64, 128)  147456      activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 64, 64, 128)  147456      activation_4[0][0]               \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 64, 64, 128)  0           conv2d_6[0][0]                   \n                                                                 add_1[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 64, 64, 128)  512         add_2[0][0]                      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 256)  294912      activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 32, 32, 256)  589824      activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 32, 32, 256)  32768       activation_5[0][0]               \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 32, 32, 256)  0           conv2d_8[0][0]                   \n                                                                 conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        add_3[0][0]                      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 32, 32, 256)  589824      activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 32, 32, 256)  589824      activation_8[0][0]               \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 32, 32, 256)  0           conv2d_11[0][0]                  \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        add_4[0][0]                      \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 16, 16, 512)  1179648     activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 512)  2359296     activation_10[0][0]              \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 512)  131072      activation_9[0][0]               \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 512)  0           conv2d_13[0][0]                  \n                                                                 conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        add_5[0][0]                      \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 16, 16, 512)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 16, 16, 512)  2359296     activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 16, 16, 512)  2359296     activation_12[0][0]              \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 512)  0           conv2d_16[0][0]                  \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        add_6[0][0]                      \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 16, 16, 512)  0           activation_13[0][0]              \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 131072)       0           average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\nfc1 (Dense)                     (None, 128)          16777344    flatten[0][0]                    \n__________________________________________________________________________________________________\nage (Dense)                     (None, 101)          13029       fc1[0][0]                        \n__________________________________________________________________________________________________\ngender (Dense)                  (None, 2)            258         fc1[0][0]                        \n==================================================================================================\nTotal params: 27,754,071\nTrainable params: 27,746,871\nNon-trainable params: 7,200\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train only last layers\nfor layer in model_custom.layers[:-5]:\n    layer.trainable = False","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#complie\nimport keras\nadam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel_custom.compile(loss='categorical_crossentropy',optimizer= 'adam', metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train_g, y_test_g, y_train_a, y_test_a=train_test_split(X_data, y_data_g,y_data_a, test_size=0.15, random_state=42,shuffle=True)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model\nmodel_custom.fit(X_train, [y_train_a, y_train_g],batch_size=512, epochs=24)","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/24\n146074/146074 [==============================] - 167s 1ms/step - loss: 3.7524 - age_loss: 3.4267 - gender_loss: 0.2351 - age_acc: 0.0761 - gender_acc: 0.9101\nEpoch 2/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.6173 - age_loss: 3.3006 - gender_loss: 0.2262 - age_acc: 0.0956 - gender_acc: 0.9134\nEpoch 3/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.5804 - age_loss: 3.2668 - gender_loss: 0.2231 - age_acc: 0.1061 - gender_acc: 0.9145\nEpoch 4/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.5531 - age_loss: 3.2419 - gender_loss: 0.2206 - age_acc: 0.1118 - gender_acc: 0.9148\nEpoch 5/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.5342 - age_loss: 3.2250 - gender_loss: 0.2186 - age_acc: 0.1170 - gender_acc: 0.9155\nEpoch 6/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.5128 - age_loss: 3.2041 - gender_loss: 0.2182 - age_acc: 0.1211 - gender_acc: 0.9158\nEpoch 7/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4960 - age_loss: 3.1886 - gender_loss: 0.2168 - age_acc: 0.1256 - gender_acc: 0.9155\nEpoch 8/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4816 - age_loss: 3.1748 - gender_loss: 0.2163 - age_acc: 0.1297 - gender_acc: 0.9162\nEpoch 9/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4679 - age_loss: 3.1619 - gender_loss: 0.2154 - age_acc: 0.1337 - gender_acc: 0.9159\nEpoch 10/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4530 - age_loss: 3.1478 - gender_loss: 0.2145 - age_acc: 0.1366 - gender_acc: 0.9162\nEpoch 11/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4401 - age_loss: 3.1362 - gender_loss: 0.2133 - age_acc: 0.1387 - gender_acc: 0.9167\nEpoch 12/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4278 - age_loss: 3.1241 - gender_loss: 0.2131 - age_acc: 0.1423 - gender_acc: 0.9166\nEpoch 13/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4181 - age_loss: 3.1146 - gender_loss: 0.2129 - age_acc: 0.1460 - gender_acc: 0.9163\nEpoch 14/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.4046 - age_loss: 3.1025 - gender_loss: 0.2115 - age_acc: 0.1487 - gender_acc: 0.9169\nEpoch 15/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3933 - age_loss: 3.0914 - gender_loss: 0.2113 - age_acc: 0.1510 - gender_acc: 0.9170\nEpoch 16/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3834 - age_loss: 3.0827 - gender_loss: 0.2101 - age_acc: 0.1523 - gender_acc: 0.9172\nEpoch 17/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3724 - age_loss: 3.0715 - gender_loss: 0.2103 - age_acc: 0.1551 - gender_acc: 0.9171\nEpoch 18/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3632 - age_loss: 3.0625 - gender_loss: 0.2101 - age_acc: 0.1579 - gender_acc: 0.9169\nEpoch 19/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3529 - age_loss: 3.0533 - gender_loss: 0.2090 - age_acc: 0.1585 - gender_acc: 0.9176\nEpoch 20/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3429 - age_loss: 3.0439 - gender_loss: 0.2084 - age_acc: 0.1620 - gender_acc: 0.9174\nEpoch 21/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3331 - age_loss: 3.0343 - gender_loss: 0.2082 - age_acc: 0.1646 - gender_acc: 0.9180\nEpoch 22/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3256 - age_loss: 3.0269 - gender_loss: 0.2081 - age_acc: 0.1651 - gender_acc: 0.9178\nEpoch 23/24\n146074/146074 [==============================] - 157s 1ms/step - loss: 3.3176 - age_loss: 3.0192 - gender_loss: 0.2077 - age_acc: 0.1670 - gender_acc: 0.9178\nEpoch 24/24\n146074/146074 [==============================] - 159s 1ms/step - loss: 3.3068 - age_loss: 3.0090 - gender_loss: 0.2073 - age_acc: 0.1692 - gender_acc: 0.9176\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<keras.callbacks.History at 0x7f5a513b7470>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}